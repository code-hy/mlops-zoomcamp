{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73be8a7e-d59d-48e4-860c-71baad5c8395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-21 16:41:31--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 108.138.245.96, 108.138.245.16, 108.138.245.225, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|108.138.245.96|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47673370 (45M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2023-01.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  45.46M  15.6MB/s    in 2.9s    \n",
      "\n",
      "2024-05-21 16:41:35 (15.6 MB/s) - ‘yellow_tripdata_2023-01.parquet’ saved [47673370/47673370]\n",
      "\n",
      "--2024-05-21 16:41:35--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Reusing existing connection to d37ci6vzurychx.cloudfront.net:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47748012 (46M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2023-02.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  45.54M  21.7MB/s    in 2.1s    \n",
      "\n",
      "2024-05-21 16:41:37 (21.7 MB/s) - ‘yellow_tripdata_2023-02.parquet’ saved [47748012/47748012]\n",
      "\n",
      "FINISHED --2024-05-21 16:41:37--\n",
      "Total wall clock time: 5.8s\n",
      "Downloaded: 2 files, 91M in 5.0s (18.1 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3288fe4-be42-4f20-a73d-82a58de362a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (634469560.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install pyarrow\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "#!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
    "\n",
    "\n",
    "# %%\n",
    "import pandas as pd # working with tabular data\n",
    "import pickle # for machine learning models\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer # Machine Learning\n",
    "from sklearn.linear_model import LinearRegression # Machine Learning\n",
    "from sklearn.linear_model import Lasso # Regularization\n",
    "from sklearn.linear_model import Ridge # Regularization\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # Loss Function\n",
    "\n",
    "\n",
    "# %%\n",
    "pip install pyarrow\n",
    "\n",
    "# %%\n",
    "\n",
    "nyc_yellow_taxi_2023_jan = pd.read_parquet('yellow_tripdata_2023-01.parquet')\n",
    "print(nyc_yellow_taxi_2023_jan)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "nyc_yellow_taxi_2023_jan.info()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "##19 columns for nyc yellow taxi jan 2023\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# Create a new column called 'duration'which calculates the length of each ride ow_taxi_2023_jan['tpep_pickup_datetime']\n",
    "nyc_yellow_taxi_2023_jan['duration'] = nyc_yellow_taxi_2023_jan['tpep_dropoff_datetime'] - nyc_yellow_taxi_2023_jan['tpep_pickup_datetime']\n",
    "nyc_yellow_taxi_2023_jan['duration'] = nyc_yellow_taxi_2023_jan['duration'].dt.total_seconds()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "#  computing standard deviation \n",
    "standard_deviation = nyc_yellow_taxi_2023_jan['duration'].std()\n",
    "print(f\"Standard deviation of duration (seconds): {standard_deviation:.2f}\")\n",
    "standard_deviation_mins = print(f\"standard deviation in minutes): {standard_deviation/60:.2f}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "#42.59 minutes for standard deviation\n",
    "# dropping outliers  - only keep those trips where duration was between 1 and 60 minutes\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "nyc_yellow_taxi_2023_jan=nyc_yellow_taxi_2023_jan[(nyc_yellow_taxi_2023_jan.duration >= 60) & (nyc_yellow_taxi_2023_jan.duration <= 3600)]\n",
    "nyc_yellow_taxi_2023_jan\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "#Our original dataset has 3066766 rows but after removing outliers we have 3009173 rows , so the percentage of original dataset is \n",
    "#3009173/3066766\n",
    "#98 percent \n",
    "\n",
    "#for applying one-hot encoding, we need to convert the two features (PuLocationID and DOLocationID) to strings ... \n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "nyc_yellow_taxi_2023_jan[categorical] = nyc_yellow_taxi_2023_jan[categorical].astype(str)\n",
    "nyc_yellow_taxi_2023_jan.info()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# turn the categorical columns into a list of dictionaries\n",
    "list_of_dicts = nyc_yellow_taxi_2023_jan[categorical].to_dict(orient='records')\n",
    "# fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# get a feature matrix from it... \n",
    "feature_matrix = dv.fit_transform(list_of_dicts)\n",
    "# convert to array\n",
    "feature_matrix_array = feature_matrix.toarray()\n",
    "# print dimensionality of feature matrix\n",
    "dimensionality = feature_matrix_array.shape\n",
    "print(\"Dimensonality:\" , dimensionality)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "#  unable to allocate 12gb for an array with the shape of 3009173 and 515  \n",
    "# training a linear regression model \n",
    "# Convert categorical columns to a dictionary\n",
    "train_dicts = nyc_yellow_taxi_2023_jan[categorical].to_dict(orient='records')\n",
    "\n",
    "# Instantiate a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# training set \n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# \n",
    "\n",
    "Y_train = nyc_yellow_taxi_2023_jan['duration'].values\n",
    "## using linear regression \n",
    "linereg = LinearRegression()\n",
    "linereg.fit(X_train,Y_train)\n",
    "## predictions\n",
    "predictions = linereg.predict(X_train) \n",
    "# root mean square error\n",
    "mean_squared_error(Y_train, predictions, squared=False)\n",
    "#Y_train\n",
    "#X_train \n",
    "#predictions\n",
    "#458.96/60\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# applying to Feb 2023 \n",
    "nyc_yellow_taxi_2023_feb = pd.read_parquet('yellow_tripdata_2023-02.parquet')\n",
    "nyc_yellow_taxi_2023_feb.info()\n",
    "# Create a new column called 'duration'which calculates the length of each ride \n",
    "nyc_yellow_taxi_2023_feb['duration'] = nyc_yellow_taxi_2023_feb['tpep_dropoff_datetime'] - nyc_yellow_taxi_2023_feb['tpep_pickup_datetime']\n",
    "nyc_yellow_taxi_2023_feb['duration'] = nyc_yellow_taxi_2023_feb['duration'].dt.total_seconds()\n",
    "# dropping outliers  - only keep those trips where duration was between 1 and 60 minutes\n",
    "\n",
    "nyc_yellow_taxi_2023_feb=nyc_yellow_taxi_2023_feb[(nyc_yellow_taxi_2023_feb.duration >= 60) & (nyc_yellow_taxi_2023_feb.duration <= 3600)]\n",
    "nyc_yellow_taxi_2023_feb\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "nyc_yellow_taxi_2023_feb[categorical] = nyc_yellow_taxi_2023_feb[categorical].astype(str)\n",
    "nyc_yellow_taxi_2023_feb.info()\n",
    "list_of_dicts = nyc_yellow_taxi_2023_feb[categorical].to_dict(orient='records')\n",
    "# training a linear regression model \n",
    "# Convert categorical columns to a dictionary\n",
    "train_dicts = nyc_yellow_taxi_2023_feb[categorical].to_dict(orient='records')\n",
    "\n",
    "# Instantiate a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# training set \n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# \n",
    "\n",
    "Y_train = nyc_yellow_taxi_2023_feb['duration'].values\n",
    "## using linear regression \n",
    "linereg = LinearRegression()\n",
    "linereg.fit(X_train,Y_train)\n",
    "## predictions\n",
    "predictions = linereg.predict(X_train) \n",
    "# root mean square error\n",
    "mean_squared_error(Y_train, predictions, squared=False)\n",
    "\n",
    "#Y_train\n",
    "#X_train \n",
    "#predictions\n",
    "466.734/60\n",
    "\n",
    "# %%\n",
    "\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
    "#pdata_2023-01.parquet')\n",
    "print(nyc_yellow_taxi_2023_jan)\n",
    "\n",
    "nyc_yellow_taxi_2023_jan.info()\n",
    "19 columns for nyc yellow taxi jan 2023\n",
    "# Create a new column called 'duration'which calculates the length of each ride \n",
    "nyc_yellow_taxi_2023_jan['duration'] = nyc_yellow_taxi_2023_jan['tpep_dropoff_datetime'] - nyc_yellow_taxi_2023_jan['tpep_pickup_datetime']\n",
    "nyc_yellow_taxi_2023_jan['duration'] = nyc_yellow_taxi_2023_jan['duration'].dt.total_seconds()\n",
    "#  computing standard deviation \n",
    "standard_deviation = nyc_yellow_taxi_2023_jan['duration'].std()\n",
    "print(f\"Standard deviation of duration (seconds): {standard_deviation:.2f}\")\n",
    "standard_deviation_mins = print(f\"standard deviation in minutes): {standard_deviation/60:.2f}\")\n",
    "42.59 minutes for standard deviation\n",
    "# dropping outliers  - only keep those trips where duration was between 1 and 60 minutes\n",
    "\n",
    "nyc_yellow_taxi_2023_jan=nyc_yellow_taxi_2023_jan[(nyc_yellow_taxi_2023_jan.duration >= 60) & (nyc_yellow_taxi_2023_jan.duration <= 3600)]\n",
    "nyc_yellow_taxi_2023_jan\n",
    "Our original dataset has 3066766 rows but after removing outliers we have 3009173 rows , so the percentage of original dataset is \n",
    "3009173/3066766\n",
    "98 percent \n",
    "for applying one-hot encoding, we need to convert the two features (PuLocationID and DOLocationID) to strings ... \n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "nyc_yellow_taxi_2023_jan[categorical] = nyc_yellow_taxi_2023_jan[categorical].astype(str)\n",
    "nyc_yellow_taxi_2023_jan.info()\n",
    "# turn the categorical columns into a list of dictionaries\n",
    "list_of_dicts = nyc_yellow_taxi_2023_jan[categorical].to_dict(orient='records')\n",
    "# fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# get a feature matrix from it... \n",
    "feature_matrix = dv.fit_transform(list_of_dicts)\n",
    "# convert to array\n",
    "feature_matrix_array = feature_matrix.toarray()\n",
    "# print dimensionality of feature matrix\n",
    "dimensionality = feature_matrix_array.shape\n",
    "print(\"Dimensonality:\" , dimensionality)\n",
    "#  unable to allocate 12gb for an array with the shape of 3009173 and 515  \n",
    "# training a linear regression model \n",
    "# Convert categorical columns to a dictionary\n",
    "train_dicts = nyc_yellow_taxi_2023_jan[categorical].to_dict(orient='records')\n",
    "\n",
    "# Instantiate a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# training set \n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# \n",
    "\n",
    "Y_train = nyc_yellow_taxi_2023_jan['duration'].values\n",
    "## using linear regression \n",
    "linereg = LinearRegression()\n",
    "linereg.fit(X_train,Y_train)\n",
    "## predictions\n",
    "predictions = linereg.predict(X_train) \n",
    "# root mean square error\n",
    "mean_squared_error(Y_train, predictions, squared=False)\n",
    "#Y_train\n",
    "#X_train \n",
    "#predictions\n",
    "458.96/60\n",
    "# applying to Feb 2023 \n",
    "nyc_yellow_taxi_2023_feb = pd.read_parquet('yellow_tripdata_2023-02.parquet')\n",
    "nyc_yellow_taxi_2023_feb.info()\n",
    "# Create a new column called 'duration'which calculates the length of each ride \n",
    "nyc_yellow_taxi_2023_feb['duration'] = nyc_yellow_taxi_2023_feb['tpep_dropoff_datetime'] - nyc_yellow_taxi_2023_feb['tpep_pickup_datetime']\n",
    "nyc_yellow_taxi_2023_feb['duration'] = nyc_yellow_taxi_2023_feb['duration'].dt.total_seconds()\n",
    "# dropping outliers  - only keep those trips where duration was between 1 and 60 minutes\n",
    "\n",
    "nyc_yellow_taxi_2023_feb=nyc_yellow_taxi_2023_feb[(nyc_yellow_taxi_2023_feb.duration >= 60) & (nyc_yellow_taxi_2023_feb.duration <= 3600)]\n",
    "nyc_yellow_taxi_2023_feb\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "nyc_yellow_taxi_2023_feb[categorical] = nyc_yellow_taxi_2023_feb[categorical].astype(str)\n",
    "nyc_yellow_taxi_2023_feb.info()\n",
    "list_of_dicts = nyc_yellow_taxi_2023_feb[categorical].to_dict(orient='records')\n",
    "# training a linear regression model \n",
    "# Convert categorical columns to a dictionary\n",
    "train_dicts = nyc_yellow_taxi_2023_feb[categorical].to_dict(orient='records')\n",
    "\n",
    "# Instantiate a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# training set \n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# \n",
    "\n",
    "Y_train = nyc_yellow_taxi_2023_feb['duration'].values\n",
    "## using linear regression \n",
    "linereg = LinearRegression()\n",
    "linereg.fit(X_train,Y_train)\n",
    "## predictions\n",
    "predictions = linereg.predict(X_train) \n",
    "# root mean square error\n",
    "mean_squared_error(Y_train, predictions, squared=False)\n",
    "#Y_train\n",
    "#X_train \n",
    "#predictions\n",
    "466.734/60\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c120b55-4899-4565-bb1d-55a8fb09b0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587dfecc-b34b-4fd0-be75-931129fe98bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
